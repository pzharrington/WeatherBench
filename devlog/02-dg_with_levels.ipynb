{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import xarray as xr\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.layers import *\n",
    "import tensorflow.keras.backend as K\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import re\n",
    "from src.score import *\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "from src.networks import *\n",
    "from src.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=str(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "datadir = '/data/stephan/WeatherBench/5.625deg/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10m_u_component_of_wind  potential_vorticity\t       total_cloud_cover\n",
      "10m_v_component_of_wind  relative_humidity\t       total_precipitation\n",
      "2m_temperature\t\t specific_humidity\t       u_component_of_wind\n",
      "constants\t\t temperature\t\t       v_component_of_wind\n",
      "geopotential\t\t temperature_850\t       vorticity\n",
      "geopotential_500\t toa_incident_solar_radiation\n"
     ]
    }
   ],
   "source": [
    "!ls $datadir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "var_dict = {\n",
    "    'geopotential': ('z', [500, 850]),\n",
    "    'toa_incident_solar_radiation': ('tisr', None),\n",
    "    'constants': ['lat2d', 'orography']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "ds = [xr.open_mfdataset(f'{datadir}/{var}/*.nc', combine='by_coords') for var in var_dict.keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "ds = xr.merge(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'geopotential': ('z', [500, 850]),\n",
       " 'toa_incident_solar_radiation': ('tisr', None),\n",
       " 'constants': ['lat2d', 'orography']}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "class DataGenerator(keras.utils.Sequence):\n",
    "    def __init__(self, ds, var_dict, lead_time, batch_size=32, shuffle=True, load=True, \n",
    "                 mean=None, std=None, output_vars=None):\n",
    "        \"\"\"\n",
    "        Data generator for WeatherBench data.\n",
    "        Template from https://stanford.edu/~shervine/blog/keras-how-to-generate-data-on-the-fly\n",
    "        Args:\n",
    "            ds: Dataset containing all variables\n",
    "            var_dict: Dictionary of the form {'var': level}. Use None for level if data is of single level\n",
    "            lead_time: Lead time in hours\n",
    "            batch_size: Batch size\n",
    "            shuffle: bool. If True, data is shuffled.\n",
    "            load: bool. If True, datadet is loaded into RAM.\n",
    "            mean: If None, compute mean from data.\n",
    "            std: If None, compute standard deviation from data.\n",
    "        \"\"\"\n",
    "\n",
    "        self.ds = ds\n",
    "        self.var_dict = var_dict\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.lead_time = lead_time\n",
    "\n",
    "        data = []\n",
    "        level_names = []\n",
    "        generic_level = xr.DataArray([1], coords={'level': [1]}, dims=['level'])\n",
    "        for long_var, params in var_dict.items():\n",
    "            if long_var == 'constants': \n",
    "                for var in params:\n",
    "                    data.append(ds[var].expand_dims(\n",
    "                        {'level': generic_level, 'time': ds.time}, (1, 0)\n",
    "                    ))\n",
    "                    level_names.append(var)\n",
    "            else:\n",
    "                var, levels = params\n",
    "                try:\n",
    "                    data.append(ds[var].sel(level=levels))\n",
    "                    level_names += [f'{var}_{level}' for level in levels]\n",
    "                except ValueError:\n",
    "                    data.append(ds[var].expand_dims({'level': generic_level}, 1))\n",
    "                    level_names.append(var)\n",
    "\n",
    "        self.data = xr.concat(data, 'level').transpose('time', 'lat', 'lon', 'level')\n",
    "        self.data['level_names'] = xr.DataArray(\n",
    "            level_names, dims=['level'], coords={'level': self.data.level})\n",
    "        if output_vars is None:\n",
    "            self.output_idxs = range(len(dg_valid.data.level))\n",
    "        else:\n",
    "            self.output_idxs = [i for i, l in enumerate(self.data.level_names.values) \n",
    "                                if any([bool(re.match(o, l)) for o in output_vars])]\n",
    "        \n",
    "        # Normalize\n",
    "        self.mean = self.data.mean(('time', 'lat', 'lon')).compute() if mean is None else mean\n",
    "#         self.std = self.data.std('time').mean(('lat', 'lon')).compute() if std is None else std\n",
    "        self.std = self.data.std(('time', 'lat', 'lon')).compute() if std is None else std\n",
    "        self.data = (self.data - self.mean) / self.std\n",
    "        \n",
    "        self.n_samples = self.data.isel(time=slice(0, -lead_time)).shape[0]\n",
    "        self.init_time = self.data.isel(time=slice(None, -lead_time)).time\n",
    "        self.valid_time = self.data.isel(time=slice(lead_time, None)).time\n",
    "\n",
    "        self.on_epoch_end()\n",
    "\n",
    "        # For some weird reason calling .load() earlier messes up the mean and std computations\n",
    "        if load: print('Loading data into RAM'); self.data.load()\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return int(np.ceil(self.n_samples / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        'Generate one batch of data'\n",
    "        idxs = self.idxs[i * self.batch_size:(i + 1) * self.batch_size]\n",
    "        X = self.data.isel(time=idxs).values\n",
    "        y = self.data.isel(time=idxs + self.lead_time, level=self.output_idxs).values\n",
    "        return X, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        self.idxs = np.arange(self.n_samples)\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "from src.data_generator import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "bs=32\n",
    "lead_time=3*24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "ds_train = ds.sel(time=slice('2015', '2015'))\n",
    "ds_valid = ds.sel(time=slice('2016', '2016'))\n",
    "ds_test = ds.sel(time=slice('2017', '2018'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "output_vars = ['z_500', 'z_850', 'tisr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "src.data_generator.DataGenerator"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DG start 10:52:54.778011\n",
      "DG normalize 10:52:54.805262\n",
      "DG load 10:52:56.258504\n",
      "Loading data into RAM\n",
      "DG done 10:52:57.190268\n",
      "DG start 10:52:57.191848\n",
      "DG normalize 10:52:57.204134\n",
      "DG load 10:52:57.210734\n",
      "Loading data into RAM\n",
      "DG done 10:52:58.120746\n",
      "CPU times: user 5.76 s, sys: 9.33 s, total: 15.1 s\n",
      "Wall time: 3.34 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "dg_train = DataGenerator(ds_train, var_dict, lead_time, batch_size=bs, load=True, \n",
    "                         output_vars=output_vars)\n",
    "dg_valid = DataGenerator(ds_train, var_dict, lead_time, batch_size=bs, mean=dg_train.mean, std=dg_train.std, \n",
    "                         shuffle=False, output_vars=output_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DG start 10:52:58.140861\n",
      "DG normalize 10:52:58.153552\n",
      "DG load 10:52:58.159698\n",
      "Loading data into RAM\n",
      "DG done 10:52:59.862208\n"
     ]
    }
   ],
   "source": [
    "dg_test = DataGenerator(ds_test, var_dict, lead_time, batch_size=bs, mean=dg_train.mean, std=dg_train.std, \n",
    "                         shuffle=False, output_vars=output_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.DataArray 'level_names' (level: 5)>\n",
       "array(['z_500', 'z_850', 'tisr', 'lat2d', 'orography'], dtype='<U9')\n",
       "Coordinates:\n",
       "  * level        (level) int64 500 850 1 1 1\n",
       "    level_names  (level) <U9 'z_500' 'z_850' 'tisr' 'lat2d' 'orography'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dg_train.data.level_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((32, 32, 64, 5), (32, 32, 64, 1))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = dg_train[0]; X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dg_train.output_idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.DataArray 'z' (level: 5)>\n",
       "array([3.48306094e+03, 1.55964335e+03, 1.44036266e+06, 5.19361462e+01,\n",
       "       8.59872249e+02])\n",
       "Coordinates:\n",
       "  * level        (level) int64 500 850 1 1 1\n",
       "    level_names  (level) <U9 'z_500' 'z_850' 'tisr' 'lat2d' 'orography'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dg_train.std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.DataArray 'z' (level: 5)>\n",
       "array([5.41249140e+04, 1.37205813e+04, 1.07486679e+06, 0.00000000e+00,\n",
       "       3.79497583e+02])\n",
       "Coordinates:\n",
       "  * level        (level) int64 500 850 1 1 1\n",
       "    level_names  (level) <U9 'z_500' 'z_850' 'tisr' 'lat2d' 'orography'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dg_train.mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "cnn = build_cnn([64, 64, 64, 64, 3], [5, 5, 5, 5, 5], (32, 64, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "cnn.compile(keras.optimizers.Adam(1e-4), 'mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "272/272 [==============================] - 6s 23ms/step - loss: 3.2339\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f40dd68b780>"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn.fit_generator(dg_train, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "preds = cnn.predict_generator(dg_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "dg = dg_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8688, 32, 64, 2)"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.DataArray 'level' (level: 2)>\n",
       "array([500,   1])\n",
       "Coordinates:\n",
       "  * level        (level) int64 500 1\n",
       "    level_names  (level) <U9 'z_500' 'u10'"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dg.data.isel(level=dg.output_idxs).level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "preds = xr.DataArray(\n",
    "    preds,\n",
    "    dims=['time', 'lat', 'lon', 'level'],\n",
    "    coords={'time': dg.valid_time, 'lat': dg.data.lat, 'lon': dg.data.lon, \n",
    "            'level': dg.data.isel(level=dg.output_idxs).level,\n",
    "            'level_names': dg.data.isel(level=dg.output_idxs).level_names\n",
    "           },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8688, 32, 64, 2), <xarray.DataArray 'level' (level: 2)>\n",
       " array([500,   1])\n",
       " Coordinates:\n",
       "   * level        (level) int64 500 1\n",
       "     level_names  (level) <U9 'z_500' 'u10', <xarray.DataArray 'level_names' (level: 2)>\n",
       " array(['z_500', 'u10'], dtype='<U9')\n",
       " Coordinates:\n",
       "   * level        (level) int64 500 1\n",
       "     level_names  (level) <U9 'z_500' 'u10')"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.shape, preds.level, preds.level_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'geopotential': ('z', [500]),\n",
       " '10m_u_component_of_wind': ('u10', None),\n",
       " 'constants': ['lat2d', 'orography']}"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dg.var_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['z_500'] [500]\n",
      "[0]\n",
      "['u10'] None\n",
      "[1]\n"
     ]
    }
   ],
   "source": [
    "das = []\n",
    "for long_var, params in dg.var_dict.items():\n",
    "    if not long_var == 'constants':\n",
    "        var, levels = params\n",
    "        var_names = [var] if levels is None else [f'{var}_{level}' for level in levels]\n",
    "        print(var_names, levels)\n",
    "        var_idxs = [i for i, v in enumerate(preds.level_names) if v in var_names]\n",
    "        print(var_idxs)\n",
    "        da = preds.isel(level=var_idxs)\n",
    "        if levels is not None: da = da.sel(level=levels).drop('level_names')\n",
    "        else: da = da.squeeze().drop('level').drop('level_names')\n",
    "        das.append({var: da})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "das = xr.merge(das)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.Dataset>\n",
       "Dimensions:  (lat: 32, level: 1, lon: 64, time: 8688)\n",
       "Coordinates:\n",
       "  * time     (time) datetime64[ns] 2015-01-04 ... 2015-12-31T23:00:00\n",
       "  * lat      (lat) float64 -87.19 -81.56 -75.94 -70.31 ... 75.94 81.56 87.19\n",
       "  * lon      (lon) float64 0.0 5.625 11.25 16.88 ... 337.5 343.1 348.8 354.4\n",
       "  * level    (level) int64 500\n",
       "Data variables:\n",
       "    z        (time, lat, lon, level) float32 -1.6765449 ... -0.17071085\n",
       "    u10      (time, lat, lon) float32 -0.71567136 -0.5935094 ... 0.08219392"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "das"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tisr']"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'tisr'.split('_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "def create_predictions(model, dg):\n",
    "    \"\"\"Create non-iterative predictions\"\"\"\n",
    "    preds = xr.DataArray(\n",
    "        model.predict_generator(dg),\n",
    "        dims=['time', 'lat', 'lon', 'level'],\n",
    "        coords={'time': dg.valid_time, 'lat': dg.data.lat, 'lon': dg.data.lon, \n",
    "                'level': dg.data.isel(level=dg.output_idxs).level,\n",
    "                'level_names': dg.data.isel(level=dg.output_idxs).level_names\n",
    "               },\n",
    "    )\n",
    "    # Unnormalize\n",
    "    preds = (preds * dg.std.isel(level=dg.output_idxs).values + \n",
    "             dg.mean.isel(level=dg.output_idxs).values)\n",
    "    unique_vars = list(set([l.split('_')[0] for l in preds.level_names.values])); unique_vars\n",
    "    \n",
    "    das = []\n",
    "    for v in unique_vars:\n",
    "        idxs = [i for i, vv in enumerate(preds.level_names.values) if vv.split('_')[0] in v]\n",
    "        print(v, idxs)\n",
    "        da = preds.isel(level=idxs).squeeze().drop('level_names')\n",
    "        if not 'level' in da.dims: da.drop('level')\n",
    "        das.append({v: da})\n",
    "    return xr.merge(das)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.create_predictions(model, dg)>"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tisr [2]\n",
      "z [0, 1]\n"
     ]
    }
   ],
   "source": [
    "preds = create_predictions(cnn, dg_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tisr', 'z']"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_vars = list(set([l.split('_')[0] for l in preds.level_names.values])); unique_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tisr [2]\n",
      "z [0, 1]\n"
     ]
    }
   ],
   "source": [
    "das = []\n",
    "for v in unique_vars:\n",
    "    idxs = [i for i, vv in enumerate(preds.level_names.values) if vv.split('_')[0] in v]\n",
    "    print(v, idxs)\n",
    "    da = preds.isel(level=idxs).squeeze().drop('level_names')\n",
    "    if not 'level' in da.dims: da.drop('level')\n",
    "    das.append({v: da})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.Dataset>\n",
       "Dimensions:  (lat: 32, level: 2, lon: 64, time: 17448)\n",
       "Coordinates:\n",
       "  * time     (time) datetime64[ns] 2017-01-04 ... 2018-12-31T23:00:00\n",
       "  * lat      (lat) float64 -87.19 -81.56 -75.94 -70.31 ... 75.94 81.56 87.19\n",
       "  * lon      (lon) float64 0.0 5.625 11.25 16.88 ... 337.5 343.1 348.8 354.4\n",
       "  * level    (level) int64 500 850\n",
       "Data variables:\n",
       "    tisr     (time, lat, lon) float64 1.089e+06 1.072e+06 ... 9.867e+03\n",
       "    z        (time, lat, lon, level) float64 5.012e+04 1.236e+04 ... 1.224e+04"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xr.merge(das)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "a = das[0]['tisr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('time', 'lat', 'lon')"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/home/stephan/miniconda3/lib/python3.6/site-packages/xarray/core/merge.py\u001b[0m(135)\u001b[0;36munique_variable\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    133 \u001b[0;31m        raise MergeError(\n",
      "\u001b[0m\u001b[0;32m    134 \u001b[0;31m            \u001b[0;34m\"conflicting values for variable {!r} on objects to be combined. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 135 \u001b[0;31m            \u001b[0;34m\"You can skip this check by specifying compat='override'.\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    136 \u001b[0;31m        )\n",
      "\u001b[0m\u001b[0;32m    137 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  u\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/home/stephan/miniconda3/lib/python3.6/site-packages/xarray/core/merge.py\u001b[0m(217)\u001b[0;36mmerge_collected\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    215 \u001b[0;31m                \u001b[0mvariables\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mvariable\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mvariable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0melements_list\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    216 \u001b[0;31m                \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 217 \u001b[0;31m                    \u001b[0mmerged_vars\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munique_variable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvariables\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    218 \u001b[0;31m                \u001b[0;32mexcept\u001b[0m \u001b[0mMergeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    219 \u001b[0;31m                    \u001b[0;32mif\u001b[0m \u001b[0mcompat\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"minimal\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  u\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/home/stephan/miniconda3/lib/python3.6/site-packages/xarray/core/merge.py\u001b[0m(544)\u001b[0;36mmerge_core\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    542 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    543 \u001b[0;31m    \u001b[0mprioritized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_priority_vars_and_indexes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maligned\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpriority_arg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 544 \u001b[0;31m    \u001b[0mvariables\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_indexes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmerge_collected\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcollected\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprioritized\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    545 \u001b[0;31m    \u001b[0massert_unique_multiindex_level_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    546 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  u\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/home/stephan/miniconda3/lib/python3.6/site-packages/xarray/core/merge.py\u001b[0m(782)\u001b[0;36mmerge\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    780 \u001b[0;31m        \u001b[0mdict_like_objects\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    781 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 782 \u001b[0;31m    \u001b[0mmerge_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmerge_core\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdict_like_objects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjoin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfill_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    783 \u001b[0;31m    \u001b[0mmerged\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_construct_direct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mmerge_result\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_asdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    784 \u001b[0;31m    \u001b[0;32mreturn\u001b[0m \u001b[0mmerged\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  u\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m<ipython-input-105-6ff341516a97>\u001b[0m(28)\u001b[0;36mcreate_predictions\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     24 \u001b[0;31m\u001b[0;31m#             var_idxs = [i for i, v in enumerate(preds.level_names) if v == var]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     25 \u001b[0;31m\u001b[0;31m#             das.append({var: preds.isel(level=var_idxs).squeeze().drop('level_names')})\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     26 \u001b[0;31m\u001b[0;31m# #             das.append({var: preds.isel(level=var_idxs)})\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     27 \u001b[0;31m        \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 28 \u001b[0;31m    \u001b[0;32mreturn\u001b[0m \u001b[0mxr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  len(das)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  das.keys()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** AttributeError: 'list' object has no attribute 'keys'\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  xr.merge(das[:2])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** xarray.core.merge.MergeError: conflicting values for variable 'level' on objects to be combined. You can skip this check by specifying compat='override'.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  xr.merge(das[:2], compat='override')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset>\n",
      "Dimensions:      (lat: 32, lon: 64, time: 17448)\n",
      "Coordinates:\n",
      "  * time         (time) datetime64[ns] 2017-01-04 ... 2018-12-31T23:00:00\n",
      "  * lat          (lat) float64 -87.19 -81.56 -75.94 -70.31 ... 75.94 81.56 87.19\n",
      "  * lon          (lon) float64 0.0 5.625 11.25 16.88 ... 337.5 343.1 348.8 354.4\n",
      "    level        int64 500\n",
      "    level_names  <U9 'z_500'\n",
      "Data variables:\n",
      "    z            (time, lat, lon) float64 5.012e+04 5.028e+04 ... 4.942e+04\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  q\n"
     ]
    }
   ],
   "source": [
    "%debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.Dataset>\n",
       "Dimensions:      (lat: 32, level: 0, lon: 64, time: 17448)\n",
       "Coordinates:\n",
       "  * time         (time) datetime64[ns] 2017-01-04 ... 2018-12-31T23:00:00\n",
       "  * lat          (lat) float64 -87.19 -81.56 -75.94 -70.31 ... 75.94 81.56 87.19\n",
       "  * lon          (lon) float64 0.0 5.625 11.25 16.88 ... 337.5 343.1 348.8 354.4\n",
       "  * level        (level) int64 \n",
       "    level_names  (level) <U9 \n",
       "Data variables:\n",
       "    z            (time, lat, lon, level) float64 \n",
       "    tisr         (time, lat, lon, level) float64 "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "z500_valid = load_test_data(f'{datadir}geopotential_500', 'z').drop('level')\n",
    "t850_valid = load_test_data(f'{datadir}temperature_850', 't')\n",
    "valid = xr.merge([z500_valid, t850_valid])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.Dataset>\n",
       "Dimensions:  (lat: 32, lon: 64, time: 17520)\n",
       "Coordinates:\n",
       "  * lon      (lon) float64 0.0 5.625 11.25 16.88 ... 337.5 343.1 348.8 354.4\n",
       "  * lat      (lat) float64 -87.19 -81.56 -75.94 -70.31 ... 75.94 81.56 87.19\n",
       "  * time     (time) datetime64[ns] 2017-01-01 ... 2018-12-31T23:00:00\n",
       "    level    int32 850\n",
       "Data variables:\n",
       "    z        (time, lat, lon) float32 dask.array<chunksize=(8760, 32, 64), meta=np.ndarray>\n",
       "    t        (time, lat, lon) float32 dask.array<chunksize=(8760, 32, 64), meta=np.ndarray>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.DataArray 'z_rmse' ()>\n",
       "array(760.22060395)\n",
       "Coordinates:\n",
       "    level    int64 500"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_weighted_rmse(preds.z.sel(level=500), ds_test.z.sel(level=500)).load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "ds = xr.open_dataset('/home/stephan/data/myWeatherBench/predictions/01-default.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.Dataset>\n",
       "Dimensions:  (lat: 32, level: 2, lon: 64, time: 17448)\n",
       "Coordinates:\n",
       "  * level    (level) int64 500 850\n",
       "  * time     (time) datetime64[ns] 2017-01-04 ... 2018-12-31T23:00:00\n",
       "  * lat      (lat) float64 -87.19 -81.56 -75.94 -70.31 ... 75.94 81.56 87.19\n",
       "  * lon      (lon) float64 0.0 5.625 11.25 16.88 ... 337.5 343.1 348.8 354.4\n",
       "Data variables:\n",
       "    z        (time, lat, lon, level) float32 ...\n",
       "    t        (time, lat, lon, level) float32 ..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.DataArray 'z' (lat: 32, lon: 64)>\n",
       "array([[nan, nan, nan, ..., nan, nan, nan],\n",
       "       [nan, nan, nan, ..., nan, nan, nan],\n",
       "       [nan, nan, nan, ..., nan, nan, nan],\n",
       "       ...,\n",
       "       [nan, nan, nan, ..., nan, nan, nan],\n",
       "       [nan, nan, nan, ..., nan, nan, nan],\n",
       "       [nan, nan, nan, ..., nan, nan, nan]], dtype=float32)\n",
       "Coordinates:\n",
       "    level    int64 850\n",
       "    time     datetime64[ns] 2017-01-04\n",
       "  * lat      (lat) float64 -87.19 -81.56 -75.94 -70.31 ... 75.94 81.56 87.19\n",
       "  * lon      (lon) float64 0.0 5.625 11.25 16.88 ... 337.5 343.1 348.8 354.4"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.z.sel(level=850).isel(time=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "ds.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'a' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-3f786850e387>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0ma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'a' is not defined"
     ]
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
