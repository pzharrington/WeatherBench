{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stephan/miniconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/stephan/miniconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/stephan/miniconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/stephan/miniconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/stephan/miniconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/stephan/miniconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import xarray as xr\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.layers import *\n",
    "import tensorflow.keras.backend as K\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "from src.score import *\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.train_nn import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=str(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir = '/data/stephan/WeatherBench/5.625deg/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10m_u_component_of_wind  potential_vorticity\t       total_cloud_cover\n",
      "10m_v_component_of_wind  relative_humidity\t       total_precipitation\n",
      "2m_temperature\t\t specific_humidity\t       u_component_of_wind\n",
      "constants\t\t temperature\t\t       v_component_of_wind\n",
      "geopotential\t\t temperature_850\t       vorticity\n",
      "geopotential_500\t toa_incident_solar_radiation\n"
     ]
    }
   ],
   "source": [
    "!ls $datadir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_dict = {\n",
    "    'geopotential': ('z', [500]),\n",
    "    '10m_u_component_of_wind': ('u10', None),\n",
    "    'constants': ['lat2d', 'orography']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = [xr.open_mfdataset(f'{datadir}/{var}/*.nc', combine='by_coords') for var in var_dict.keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = xr.merge(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'geopotential': ('z', [500]),\n",
       " '10m_u_component_of_wind': ('u10', None),\n",
       " 'constants': ['lat2d', 'orography']}"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(keras.utils.Sequence):\n",
    "    def __init__(self, ds, var_dict, lead_time, batch_size=32, shuffle=True, load=True, \n",
    "                 mean=None, std=None, output_vars=None):\n",
    "        \"\"\"\n",
    "        Data generator for WeatherBench data.\n",
    "        Template from https://stanford.edu/~shervine/blog/keras-how-to-generate-data-on-the-fly\n",
    "        Args:\n",
    "            ds: Dataset containing all variables\n",
    "            var_dict: Dictionary of the form {'var': level}. Use None for level if data is of single level\n",
    "            lead_time: Lead time in hours\n",
    "            batch_size: Batch size\n",
    "            shuffle: bool. If True, data is shuffled.\n",
    "            load: bool. If True, datadet is loaded into RAM.\n",
    "            mean: If None, compute mean from data.\n",
    "            std: If None, compute standard deviation from data.\n",
    "        \"\"\"\n",
    "\n",
    "        self.ds = ds\n",
    "        self.var_dict = var_dict\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.lead_time = lead_time\n",
    "\n",
    "        data = []\n",
    "        level_names = []\n",
    "        generic_level = xr.DataArray([1], coords={'level': [1]}, dims=['level'])\n",
    "        for long_var, params in var_dict.items():\n",
    "            if long_var == 'constants': \n",
    "                for var in params:\n",
    "                    data.append(ds[var].expand_dims(\n",
    "                        {'level': generic_level, 'time': ds.time}, (1, 0)\n",
    "                    ))\n",
    "                    level_names.append(var)\n",
    "            else:\n",
    "                var, levels = params\n",
    "                try:\n",
    "                    data.append(ds[var].sel(level=levels))\n",
    "                    level_names += [f'{var}_{level}' for level in levels]\n",
    "                except ValueError:\n",
    "                    data.append(ds[var].expand_dims({'level': generic_level}, 1))\n",
    "                    level_names.append(var)\n",
    "\n",
    "        self.data = xr.concat(data, 'level').transpose('time', 'lat', 'lon', 'level')\n",
    "        self.data['level_names'] = xr.DataArray(\n",
    "            level_names, dims=['level'], coords={'level': self.data.level})\n",
    "        if output_vars is None:\n",
    "            self.output_idxs = range(len(dg_valid.data.level))\n",
    "        else:\n",
    "            self.output_idxs = [i for i, l in enumerate(self.data.level_names.values) \n",
    "                                if any([bool(re.match(o, l)) for o in output_vars])]\n",
    "        \n",
    "        # Normalize\n",
    "        self.mean = self.data.mean(('time', 'lat', 'lon')).compute() if mean is None else mean\n",
    "#         self.std = self.data.std('time').mean(('lat', 'lon')).compute() if std is None else std\n",
    "        self.std = self.data.std(('time', 'lat', 'lon')).compute() if std is None else std\n",
    "        self.data = (self.data - self.mean) / self.std\n",
    "        \n",
    "        self.n_samples = self.data.isel(time=slice(0, -lead_time)).shape[0]\n",
    "        self.init_time = self.data.isel(time=slice(None, -lead_time)).time\n",
    "        self.valid_time = self.data.isel(time=slice(lead_time, None)).time\n",
    "\n",
    "        self.on_epoch_end()\n",
    "\n",
    "        # For some weird reason calling .load() earlier messes up the mean and std computations\n",
    "        if load: print('Loading data into RAM'); self.data.load()\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return int(np.ceil(self.n_samples / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        'Generate one batch of data'\n",
    "        idxs = self.idxs[i * self.batch_size:(i + 1) * self.batch_size]\n",
    "        X = self.data.isel(time=idxs).values\n",
    "        y = self.data.isel(time=idxs + self.lead_time, level=self.output_idxs).values\n",
    "        return X, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        self.idxs = np.arange(self.n_samples)\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs=32\n",
    "lead_time=3*24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train = ds.sel(time=slice('2015', '2015'))\n",
    "ds_valid = ds.sel(time=slice('2016', '2016'))\n",
    "ds_test = ds.sel(time=slice('2017', '2018'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_vars = ['z_*', 'u10']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data into RAM\n",
      "Loading data into RAM\n",
      "CPU times: user 6.48 s, sys: 59.3 s, total: 1min 5s\n",
      "Wall time: 29.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "dg_train = DataGenerator(ds_train, var_dict, lead_time, batch_size=bs, load=True, \n",
    "                         output_vars=output_vars)\n",
    "dg_valid = DataGenerator(ds_train, var_dict, lead_time, batch_size=bs, mean=dg_train.mean, std=dg_train.std, \n",
    "                         shuffle=False, output_vars=output_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data into RAM\n"
     ]
    }
   ],
   "source": [
    "dg_test = DataGenerator(ds_test, var_dict, lead_time, batch_size=bs, mean=dg_train.mean, std=dg_train.std, \n",
    "                         shuffle=False, output_vars=output_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.DataArray 'level_names' (level: 4)>\n",
       "array(['z_500', 'u10', 'lat2d', 'orography'], dtype='<U9')\n",
       "Coordinates:\n",
       "  * level        (level) int64 500 1 1 1\n",
       "    level_names  (level) <U9 'z_500' 'u10' 'lat2d' 'orography'"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dg_train.data.level_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((32, 32, 64, 4), (32, 32, 64, 2))"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = dg_train[0]; X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1]"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dg_train.output_idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.DataArray 'z' (level: 4)>\n",
       "array([3483.06093502,    5.62151846,   51.93614619,  859.8722486 ])\n",
       "Coordinates:\n",
       "  * level        (level) int64 500 1 1 1\n",
       "    level_names  (level) <U9 'z_500' 'u10' 'lat2d' 'orography'"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dg_train.std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.DataArray 'z' (level: 4)>\n",
       "array([ 5.41249140e+04, -3.31912328e-04,  0.00000000e+00,  3.79497583e+02])\n",
       "Coordinates:\n",
       "  * level        (level) int64 500 1 1 1\n",
       "    level_names  (level) <U9 'z_500' 'u10' 'lat2d' 'orography'"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dg_train.mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = build_cnn([64, 64, 64, 64, 2], [5, 5, 5, 5, 5], (32, 64, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.compile(keras.optimizers.Adam(1e-4), 'mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "272/272 [==============================] - 6s 24ms/step - loss: 10.5980\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f8440197128>"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn.fit_generator(dg_train, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = cnn.predict_generator(dg_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "dg = dg_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8688, 32, 64, 2)"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.DataArray 'level' (level: 2)>\n",
       "array([500,   1])\n",
       "Coordinates:\n",
       "  * level        (level) int64 500 1\n",
       "    level_names  (level) <U9 'z_500' 'u10'"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dg.data.isel(level=dg.output_idxs).level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = xr.DataArray(\n",
    "    preds,\n",
    "    dims=['time', 'lat', 'lon', 'level'],\n",
    "    coords={'time': dg.valid_time, 'lat': dg.data.lat, 'lon': dg.data.lon, \n",
    "            'level': dg.data.isel(level=dg.output_idxs).level,\n",
    "            'level_names': dg.data.isel(level=dg.output_idxs).level_names\n",
    "           },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8688, 32, 64, 2), <xarray.DataArray 'level' (level: 2)>\n",
       " array([500,   1])\n",
       " Coordinates:\n",
       "   * level        (level) int64 500 1\n",
       "     level_names  (level) <U9 'z_500' 'u10', <xarray.DataArray 'level_names' (level: 2)>\n",
       " array(['z_500', 'u10'], dtype='<U9')\n",
       " Coordinates:\n",
       "   * level        (level) int64 500 1\n",
       "     level_names  (level) <U9 'z_500' 'u10')"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.shape, preds.level, preds.level_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'geopotential': ('z', [500]),\n",
       " '10m_u_component_of_wind': ('u10', None),\n",
       " 'constants': ['lat2d', 'orography']}"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dg.var_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['z_500'] [500]\n",
      "[0]\n",
      "['u10'] None\n",
      "[1]\n"
     ]
    }
   ],
   "source": [
    "das = []\n",
    "for long_var, params in dg.var_dict.items():\n",
    "    if not long_var == 'constants':\n",
    "        var, levels = params\n",
    "        var_names = [var] if levels is None else [f'{var}_{level}' for level in levels]\n",
    "        print(var_names, levels)\n",
    "        var_idxs = [i for i, v in enumerate(preds.level_names) if v in var_names]\n",
    "        print(var_idxs)\n",
    "        da = preds.isel(level=var_idxs)\n",
    "        if levels is not None: da = da.sel(level=levels).drop('level_names')\n",
    "        else: da = da.squeeze().drop('level').drop('level_names')\n",
    "        das.append({var: da})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "das = xr.merge(das)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.Dataset>\n",
       "Dimensions:  (lat: 32, level: 1, lon: 64, time: 8688)\n",
       "Coordinates:\n",
       "  * time     (time) datetime64[ns] 2015-01-04 ... 2015-12-31T23:00:00\n",
       "  * lat      (lat) float64 -87.19 -81.56 -75.94 -70.31 ... 75.94 81.56 87.19\n",
       "  * lon      (lon) float64 0.0 5.625 11.25 16.88 ... 337.5 343.1 348.8 354.4\n",
       "  * level    (level) int64 500\n",
       "Data variables:\n",
       "    z        (time, lat, lon, level) float32 -1.6765449 ... -0.17071085\n",
       "    u10      (time, lat, lon) float32 -0.71567136 -0.5935094 ... 0.08219392"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "das"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_predictions(model, dg):\n",
    "    \"\"\"Create non-iterative predictions\"\"\"\n",
    "    preds = xr.DataArray(\n",
    "        model.predict_generator(dg),\n",
    "        dims=['time', 'lat', 'lon', 'level'],\n",
    "        coords={'time': dg.valid_time, 'lat': dg.data.lat, 'lon': dg.data.lon, \n",
    "                'level': dg.data.isel(level=dg.output_idxs).level,\n",
    "                'level_names': dg.data.isel(level=dg.output_idxs).level_names\n",
    "               },\n",
    "    )\n",
    "    # Unnormalize\n",
    "    preds = (preds * dg.std.isel(level=dg.output_idxs).values + \n",
    "             dg.mean.isel(level=dg.output_idxs).values)\n",
    "    \n",
    "    das = []\n",
    "    for long_var, params in dg.var_dict.items():\n",
    "        if not long_var == 'constants':\n",
    "            var, levels = params\n",
    "            var_idxs = [i for i, v in enumerate(preds.level_names) if v == var]\n",
    "            das.append({var: preds.isel(level=var_idxs).squeeze().drop('level_names')})\n",
    "    return xr.merge(das)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = create_predictions(cnn, dg_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.Dataset>\n",
       "Dimensions:  (lat: 32, level: 2, lon: 64, time: 8688)\n",
       "Coordinates:\n",
       "  * time     (time) datetime64[ns] 2015-01-04 ... 2015-12-31T23:00:00\n",
       "  * lat      (lat) float64 -87.19 -81.56 -75.94 -70.31 ... 75.94 81.56 87.19\n",
       "  * lon      (lon) float64 0.0 5.625 11.25 16.88 ... 337.5 343.1 348.8 354.4\n",
       "  * level    (level) int64 500 1000\n",
       "Data variables:\n",
       "    z        (time, lat, lon, level) float32 -1.5707413 ... 0.6681948\n",
       "    u10      (time, lat, lon) float32 -0.611318 -0.54330826 ... 0.1051542"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "z500_valid = load_test_data(f'{datadir}geopotential_500', 'z').drop('level')\n",
    "t850_valid = load_test_data(f'{datadir}temperature_850', 't')\n",
    "valid = xr.merge([z500_valid, t850_valid])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.Dataset>\n",
       "Dimensions:  (lat: 32, lon: 64, time: 17520)\n",
       "Coordinates:\n",
       "  * lon      (lon) float64 0.0 5.625 11.25 16.88 ... 337.5 343.1 348.8 354.4\n",
       "  * lat      (lat) float64 -87.19 -81.56 -75.94 -70.31 ... 75.94 81.56 87.19\n",
       "  * time     (time) datetime64[ns] 2017-01-01 ... 2018-12-31T23:00:00\n",
       "    level    int32 850\n",
       "Data variables:\n",
       "    z        (time, lat, lon) float32 dask.array<chunksize=(8760, 32, 64), meta=np.ndarray>\n",
       "    t        (time, lat, lon) float32 dask.array<chunksize=(8760, 32, 64), meta=np.ndarray>"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "geopotential_500hPa_1979_5.625deg.nc  geopotential_500hPa_1999_5.625deg.nc\n",
      "geopotential_500hPa_1980_5.625deg.nc  geopotential_500hPa_2000_5.625deg.nc\n",
      "geopotential_500hPa_1981_5.625deg.nc  geopotential_500hPa_2001_5.625deg.nc\n",
      "geopotential_500hPa_1982_5.625deg.nc  geopotential_500hPa_2002_5.625deg.nc\n",
      "geopotential_500hPa_1983_5.625deg.nc  geopotential_500hPa_2003_5.625deg.nc\n",
      "geopotential_500hPa_1984_5.625deg.nc  geopotential_500hPa_2004_5.625deg.nc\n",
      "geopotential_500hPa_1985_5.625deg.nc  geopotential_500hPa_2005_5.625deg.nc\n",
      "geopotential_500hPa_1986_5.625deg.nc  geopotential_500hPa_2006_5.625deg.nc\n",
      "geopotential_500hPa_1987_5.625deg.nc  geopotential_500hPa_2007_5.625deg.nc\n",
      "geopotential_500hPa_1988_5.625deg.nc  geopotential_500hPa_2008_5.625deg.nc\n",
      "geopotential_500hPa_1989_5.625deg.nc  geopotential_500hPa_2009_5.625deg.nc\n",
      "geopotential_500hPa_1990_5.625deg.nc  geopotential_500hPa_2010_5.625deg.nc\n",
      "geopotential_500hPa_1991_5.625deg.nc  geopotential_500hPa_2011_5.625deg.nc\n",
      "geopotential_500hPa_1992_5.625deg.nc  geopotential_500hPa_2012_5.625deg.nc\n",
      "geopotential_500hPa_1993_5.625deg.nc  geopotential_500hPa_2013_5.625deg.nc\n",
      "geopotential_500hPa_1994_5.625deg.nc  geopotential_500hPa_2014_5.625deg.nc\n",
      "geopotential_500hPa_1995_5.625deg.nc  geopotential_500hPa_2015_5.625deg.nc\n",
      "geopotential_500hPa_1996_5.625deg.nc  geopotential_500hPa_2016_5.625deg.nc\n",
      "geopotential_500hPa_1997_5.625deg.nc  geopotential_500hPa_2017_5.625deg.nc\n",
      "geopotential_500hPa_1998_5.625deg.nc  geopotential_500hPa_2018_5.625deg.nc\n"
     ]
    }
   ],
   "source": [
    "!ls $datadir/geopotential_500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.DataArray 'z_rmse' ()>\n",
       "array(55647.16552956)\n",
       "Coordinates:\n",
       "    level    int64 500"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_weighted_rmse(preds.z.sel(level=500), ds_train.z.sel(level=500)).load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = xr.open_dataset('/home/stephan/data/myWeatherBench/predictions/01-default.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.Dataset>\n",
       "Dimensions:  (lat: 32, level: 2, lon: 64, time: 17448)\n",
       "Coordinates:\n",
       "  * level    (level) int64 500 850\n",
       "  * time     (time) datetime64[ns] 2017-01-04 ... 2018-12-31T23:00:00\n",
       "  * lat      (lat) float64 -87.19 -81.56 -75.94 -70.31 ... 75.94 81.56 87.19\n",
       "  * lon      (lon) float64 0.0 5.625 11.25 16.88 ... 337.5 343.1 348.8 354.4\n",
       "Data variables:\n",
       "    z        (time, lat, lon, level) float32 ...\n",
       "    t        (time, lat, lon, level) float32 ..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.DataArray 'z' (lat: 32, lon: 64)>\n",
       "array([[nan, nan, nan, ..., nan, nan, nan],\n",
       "       [nan, nan, nan, ..., nan, nan, nan],\n",
       "       [nan, nan, nan, ..., nan, nan, nan],\n",
       "       ...,\n",
       "       [nan, nan, nan, ..., nan, nan, nan],\n",
       "       [nan, nan, nan, ..., nan, nan, nan],\n",
       "       [nan, nan, nan, ..., nan, nan, nan]], dtype=float32)\n",
       "Coordinates:\n",
       "    level    int64 850\n",
       "    time     datetime64[ns] 2017-01-04\n",
       "  * lat      (lat) float64 -87.19 -81.56 -75.94 -70.31 ... 75.94 81.56 87.19\n",
       "  * lon      (lon) float64 0.0 5.625 11.25 16.88 ... 337.5 343.1 348.8 354.4"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.z.sel(level=850).isel(time=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'a' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-3f786850e387>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0ma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'a' is not defined"
     ]
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
