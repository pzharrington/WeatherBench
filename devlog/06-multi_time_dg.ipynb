{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import tensorflow.keras as keras\n",
    "import datetime\n",
    "import pdb\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "datadir = '/data/stephan/WeatherBench/5.625deg/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "var_dict = {\n",
    "    'geopotential': ('z', [500]),\n",
    "    'temperature': ('t', [850]),\n",
    "    'constants': ['lat2d', 'orography', 'lsm']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "output_vars = ['z_500', 't_850']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "ds = xr.merge([xr.open_mfdataset(f'{datadir}/{var}/*.nc', combine='by_coords') for var in var_dict.keys()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "ds_train = ds.sel(time=slice('2015', '2015'))\n",
    "ds_valid = ds.sel(time=slice('2016', '2016'))\n",
    "ds_test = ds.sel(time=slice('2017', '2018'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "lead_time=72\n",
    "filters = [128, 128, 128, 128, 128, 128, 2]\n",
    "kernels = [5, 5, 5, 5, 5, 5, 5]\n",
    "norm_subsample = 60000\n",
    "data_subsample = 1\n",
    "lr = 0.5e-4\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "class DataGenerator(keras.utils.Sequence):\n",
    "    def __init__(self, ds, var_dict, lead_time, batch_size=32, shuffle=True, load=True,\n",
    "                 mean=None, std=None, output_vars=None, data_subsample=1, norm_subsample=1,\n",
    "                 nt_in=1, dt_in=1):\n",
    "        \"\"\"\n",
    "        Data generator for WeatherBench data.\n",
    "        Template from https://stanford.edu/~shervine/blog/keras-how-to-generate-data-on-the-fly\n",
    "        Args:\n",
    "            ds: Dataset containing all variables\n",
    "            var_dict: Dictionary of the form {'var': level}. Use None for level if data is of single level\n",
    "            lead_time: Lead time in hours\n",
    "            batch_size: Batch size\n",
    "            shuffle: bool. If True, data is shuffled.\n",
    "            load: bool. If True, datadet is loaded into RAM.\n",
    "            mean: If None, compute mean from data.\n",
    "            std: If None, compute standard deviation from data.\n",
    "        \"\"\"\n",
    "        print('DG start', datetime.datetime.now().time())\n",
    "        self.ds = ds\n",
    "        self.var_dict = var_dict\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.lead_time = lead_time\n",
    "        self.nt_in = nt_in\n",
    "        self.dt_in = dt_in\n",
    "\n",
    "        data = []\n",
    "        level_names = []\n",
    "        generic_level = xr.DataArray([1], coords={'level': [1]}, dims=['level'])\n",
    "        for long_var, params in var_dict.items():\n",
    "            if long_var == 'constants':\n",
    "                for var in params:\n",
    "                    data.append(ds[var].expand_dims(\n",
    "                        {'level': generic_level, 'time': ds.time}, (1, 0)\n",
    "                    ))\n",
    "                    level_names.append(var)\n",
    "            else:\n",
    "                var, levels = params\n",
    "                try:\n",
    "                    data.append(ds[var].sel(level=levels))\n",
    "                    level_names += [f'{var}_{level}' for level in levels]\n",
    "                except ValueError:\n",
    "                    data.append(ds[var].expand_dims({'level': generic_level}, 1))\n",
    "                    level_names.append(var)\n",
    "\n",
    "        self.data = xr.concat(data, 'level').transpose('time', 'lat', 'lon', 'level')\n",
    "        self.data['level_names'] = xr.DataArray(\n",
    "            level_names, dims=['level'], coords={'level': self.data.level})\n",
    "        if output_vars is None:\n",
    "            self.output_idxs = range(len(self.data.level))\n",
    "        else:\n",
    "            self.output_idxs = [i for i, l in enumerate(self.data.level_names.values)\n",
    "                                if any([bool(re.match(o, l)) for o in output_vars])]\n",
    "\n",
    "        # Subsample\n",
    "        self.data = self.data.isel(time=slice(0, None, data_subsample))\n",
    "        self.dt = self.data.time.diff('time')[0].values / np.timedelta64(1, 'h')\n",
    "        assert (self.lead_time / self.dt).is_integer(), \"lead_time and dt not compatible.\"\n",
    "        self.nt = int(self.lead_time / self.dt)\n",
    "\n",
    "        # Normalize\n",
    "        print('DG normalize', datetime.datetime.now().time())\n",
    "        self.mean = self.data.isel(time=slice(0, None, norm_subsample)).mean(\n",
    "            ('time', 'lat', 'lon')).compute() if mean is None else mean\n",
    "        #         self.std = self.data.std('time').mean(('lat', 'lon')).compute() if std is None else std\n",
    "        self.std = self.data.isel(time=slice(0, None, norm_subsample)).std(\n",
    "            ('time', 'lat', 'lon')).compute() if std is None else std\n",
    "        self.data = (self.data - self.mean) / self.std\n",
    "\n",
    "        self.n_samples = self.data.isel(time=slice(0, -self.nt)).shape[0]\n",
    "        self.init_time = self.data.isel(time=slice(0, -self.nt)).time\n",
    "        self.valid_time = self.data.isel(time=slice(self.nt, None)).time\n",
    "\n",
    "        self.on_epoch_end()\n",
    "\n",
    "        # For some weird reason calling .load() earlier messes up the mean and std computations\n",
    "        print('DG load', datetime.datetime.now().time())\n",
    "        if load: print('Loading data into RAM'); self.data.load()\n",
    "        print('DG done', datetime.datetime.now().time())\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return int(np.ceil(self.n_samples / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        'Generate one batch of data'\n",
    "        idxs = self.idxs[i * self.batch_size:(i + 1) * self.batch_size]\n",
    "        X = self.data.isel(time=idxs).values\n",
    "        if self.nt_in > 1:\n",
    "            X = np.concatenate([\n",
    "                self.data.isel(time=idxs-nt_in*self.dt_in).values for nt_in in range(self.nt_in-1, 0, -1)\n",
    "            ] + [X], axis=-1)\n",
    "        y = self.data.isel(time=idxs + self.nt, level=self.output_idxs).values\n",
    "        return X, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        self.idxs = np.arange(self.n_samples - (self.nt_in * self.dt_in) + 1)\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.idxs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 1]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(range(3-1, 0, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DG start 20:44:58.263098\n",
      "DG normalize 20:44:58.287165\n",
      "DG load 20:44:59.323206\n",
      "Loading data into RAM\n",
      "DG done 20:45:00.464060\n"
     ]
    }
   ],
   "source": [
    "dg_train = DataGenerator(\n",
    "    ds_train, var_dict, lead_time, batch_size=batch_size, output_vars=output_vars,\n",
    "    data_subsample=data_subsample, norm_subsample=norm_subsample, nt_in=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "for i in range(len(dg_train)):\n",
    "    X, y = dg_train[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128, 32, 64, 50)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "a = dg_train.data.isel(time=dg_train.idxs[:10]).values\n",
    "b = dg_train.data.isel(time=dg_train.idxs[:10]+1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 32, 64, 10)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.concatenate([a, b], axis=-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.DataArray 'time' (time: 10)>\n",
       "array(['2015-10-05T15:00:00.000000000', '2015-11-14T22:00:00.000000000',\n",
       "       '2015-02-19T16:00:00.000000000', '2015-01-30T02:00:00.000000000',\n",
       "       '2015-03-11T08:00:00.000000000', '2015-06-05T09:00:00.000000000',\n",
       "       '2015-11-15T15:00:00.000000000', '2015-02-06T09:00:00.000000000',\n",
       "       '2015-06-24T08:00:00.000000000', '2015-09-22T06:00:00.000000000'],\n",
       "      dtype='datetime64[ns]')\n",
       "Coordinates:\n",
       "  * time     (time) datetime64[ns] 2015-10-05T15:00:00 ... 2015-09-22T06:00:00\n",
       "Attributes:\n",
       "    long_name:  time"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
